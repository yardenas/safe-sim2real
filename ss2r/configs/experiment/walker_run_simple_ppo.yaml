# @package _global_
defaults:
  - override /environment: walker
  - override /agent: ppo
  - _self_

environment:
  task_name: SafeWalkerRun

training:
  num_timesteps: 150000000
  safe: true
  train_domain_randomization: false
  eval_domain_randomization: false
  safety_budget: 100
  num_eval_episodes: 1
  num_envs: 1024

agent:
  reward_scaling: 10.0
  normalize_observations: true
  unroll_length: 30
  num_minibatches: 32
  num_updates_per_batch: 16
  discounting: 0.995
  safety_discounting: 0.99
  learning_rate: 0.001
  entropy_cost: 0.05
  batch_size: 1024
  safety_gae_lambda: 0.0
  penalizer:
    initial_lagrange_multiplier: 0.2
    multiplier_lr: 1e-4